<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="SpeedTuning Project Page">
  <meta property="og:title" content="SpeedTuning" />
  <meta property="og:description" content="SpeedTuning Project Page" />
  <meta property="og:url" content="https://daivdyuan.github.io/speed-tuning/" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="SpeedTuning Stanford AI Lab">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SpeedTuning: Speeding Up Policy Execution with Lightweight Reinforcement Learning</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">SpeedTuning: Speeding Up Policy Execution with Lightweight
              Reinforcement Learning</h1>
            <div class="is-size-4 publication-authors">

              <span class="author-block">
                <a href="https://www.linkedin.com/in/dewei-yuan">David D. Yuan</a>,</span>
              <span class="author-block"></span>
              <a href="https://tonyzhaozh.github.io/">Tony Z. Zhao</a>,

              <span class="author-block">
                <a href="https://kayburns.github.io/">Kaylee Burns</a>,
              </span>

              <span class="author-block">
                <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Stanford University</span><br>
              <span class="author-block">ICRA 2025</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./static/pdfs/speedtuning_icra.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false"
                        data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 384 512" data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                        </path>
                      </svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Conference Paper</span>
                  </a>
                </span>
                
                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/DaivdYuan/SpeedTuning/tree/main" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code (WIP)</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="" target="_blank"
                class="external-link button is-normal is-rounded">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv (WIP)</span>
              </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/icra2025_final.mp4" width="100%" type="video/mp4">
        </video>
      </div>
    </div>
  </section>
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              While learned robotic policies hold promise for advancing
generalizable manipulation, their practical deployment
is often hindered by suboptimal execution speeds. Imitation
learning policies are inherently limited by hardware constraints
and the speed of the operator during data collection. In addition,
there are no established methods for accelerating policies
learned via imitation, and the empirical relationship between
execution speed and task success remains underexplored. To
address these issues, we introduce SpeedTuning, a reinforcement
learning framework specifically designed to enhance the
speed of manipulation policies. SpeedTuning learns to predict
the optimal execution speed for actions, thereby complementing
a base policy without necessitating additional data collection.
We provide empirical evidence that SpeedTuning achieves
substantial improvements in execution speed, exceeding 2.4x
speed-up, while preserving an adequate success rate compared
to both the original task policy and straightforward speedup
methods such as linear interpolation at a fixed speed.
We evaluate our approach across a diverse set of dynamic
and precise tasks, including pouring, throwing, and picking,
demonstrating its effectiveness and robustness in enhancing
real-world robotic manipulation. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <section class="hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="publication-image">
            <br>
            <br>
            <br>
            <img src="static/images/Speed_tuning_teaser.svg" width="1200px">
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-fullhd">
      <div class="hero-body">
        <div class="columns is-centered">
          <div class="column is-two-thirds">
            <br>
            <p class="has-text-justified">
              SpeedTuning is a reinforcement learning framework designed to optimize both execution speed and task success for learned manipulation policies.
              The left panel presents a schematic of SpeedTuning augmenting an imitation learning policy, where it outputs a speed multiplier to modulate the execution
              of predicted actions. This speed policy is optimized using reinforcement learning.
            </p>
            <br>
            <p>
              The right panel illustrates performance on the Tea Bag Disposal task,
with the upper half depicting speed versus task progress and the lower half showing the speed multipliers predicted at different stages. For critical actions,
such as grasping the tea bag (yellow marker), the policy selects a lower speed (2x) to ensure precise timing, whereas for less demanding stages, such as
the final phase of discarding the tea bag (purple marker), a higher speed (4x) is applied to expedite execution.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>To be released by ICRA 2025</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p></p>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>,
              courtesy of <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, <a href="https://peract.github.io/">PerAct</a>, and <a href="https://emprise.cs.cornell.edu/flair/"> FLAIR.
            <p></p>
          </a></div><a href="https://emprise.cs.cornell.edu/flair/">
        </a></div><a href="https://emprise.cs.cornell.edu/flair/">
      </a></div><a href="https://emprise.cs.cornell.edu/flair/">
    </a></div><a href="https://emprise.cs.cornell.edu/flair/">
  </a></footer>
</body>

</html>